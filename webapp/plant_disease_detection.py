# -*- coding: utf-8 -*-
"""Plant disease detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p_O39hjZ9J9CzX2lDWWqH_rNa8cp-mg1
"""

from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model, load_model
from keras.layers import Dropout, Flatten, Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping
import tensorflow as tf
import numpy as np
from sklearn import metrics
tf.logging.set_verbosity(tf.logging.ERROR)
import os

img_width, img_height = 224, 224
nb_train_samples = 135
nb_validation_samples = 35
batch_size = 5
epochs = 1

from google.colab import drive
drive.mount('/content/drive')

# !pwd

import shutil
shutil.move("drive/My Drive/plant-leaf.rar", "plant-leaf.rar")
get_ipython().system_raw("unrar x plant-leaf.rar")
shutil.move("plant-leaf.rar", "drive/My Drive/plant-leaf.rar")

# get_ipython().system_raw("unrar x plant-leaf")

train_data_dir = 'plant-leaf/train'
test_data_dir = 'plant-leaf/test'

shutil.move("train_aug", "drive/My Drive/train_aug")

shutil.move("drive/My Drive/train_aug", "train_aug")

"""# VGG16"""

vgg16 = applications.VGG16(weights = "imagenet", include_top = False, input_shape = (img_width, img_height, 3))

vgg16.layers

# !rm -rf test_aug

# os.mkdir('saved')
train_aug = 'train_aug'
test_aug = 'test_aug'
os.mkdir(train_aug)
os.mkdir(test_aug)

# Freeze the layers which you don't want to train. Here I am freezing the all the layers.
for layer in vgg16.layers[:11]:
    layer.trainable = False

# Adding custom Layers 
x = vgg16.output
x = Flatten()(x)
x = Dense(1024, activation = "relu")(x)
x = Dropout(0.5)(x)
x = Dense(512, activation = "relu")(x)
x = Dropout(0.5)(x)
predictions = Dense(2, activation = "softmax")(x)

# creating the final model 
vgg16_final = Model(input = vgg16.input, output = predictions)

# compile the model
sgd = optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)
# rmsprop = optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)
# adagrad = optimizers.Adagrad(lr=0.0001, epsilon=None, decay=0.0)
# adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
vgg16_final.compile(loss = "binary_crossentropy", optimizer = sgd, metrics = ["accuracy"])

# Initiate the train and test generators with data Augumentation 
train_datagen = ImageDataGenerator(
                rescale = 1./255,
                horizontal_flip = True,
                fill_mode = "nearest",
                zoom_range = 0.3,
                width_shift_range = 0.3,
                height_shift_range = 0.3,
                rotation_range = 30)

train_generator = train_datagen.flow_from_directory(
                  train_data_dir,
                  target_size = (img_height, img_width),
                  batch_size = batch_size, 
                  class_mode = "categorical", shuffle = False,
                  save_to_dir=train_aug, save_prefix='image', save_format='png')

test_datagen = ImageDataGenerator(
                rescale = 1./255,
                horizontal_flip = True,
                fill_mode = "nearest",
                zoom_range = 0.3,
                width_shift_range = 0.3,
                height_shift_range = 0.3,
                rotation_range = 30
                )

test_generator = test_datagen.flow_from_directory(test_data_dir,
                                            target_size = (img_height, img_width),
                                            class_mode = "categorical", shuffle = False,
                                            save_to_dir=test_aug, save_prefix='image', save_format='png')


# Save the model according to the conditions  
checkpoint = ModelCheckpoint('saved/weights.{epoch:02d}-{val_loss:.2f}.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)
# early = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, mode = 'auto')


# Train the model
# vgg16_final.fit_generator(train_generator,
#                           samples_per_epoch = nb_train_samples,
#                           epochs = epochs,
#                           validation_data = test_generator,
#                           nb_val_samples = nb_validation_samples,
#                           callbacks = [checkpoint, early])

vgg16_final.fit_generator(train_generator,
                          samples_per_epoch = nb_train_samples,
                          epochs = epochs,
                          validation_data = test_generator,
                          nb_val_samples = nb_validation_samples,
                          callbacks = [checkpoint])

# Loading the trained model
vgg16_final = load_model('saved/weights.08-1.57.h5')

score, acc = vgg16_final.evaluate_generator(test_generator, verbose = 0)

score

print('Test Accuracy: {}%' .format(acc * 100))

"""# Confusion Matrix"""

# Confusion Matrix and Classification Report
Y_pred = vgg16_final.predict_generator(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
cm = metrics.confusion_matrix(test_generator.classes, y_pred)
print(cm)
acc = 100 * (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])
print('\nAccuracy: ', acc, '%')

test_generator.classes

y_pred

